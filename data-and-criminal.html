<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="index.css">
    <title>exam-3</title>
</head>

<body class="main-body">
    <nav class="navigation">

        <a href="./index.html" class="navigation-text">home</a>
        <a href="./ai.html" class="navigation-text">Artificial Intelligence / Technology</a>
        <a href="./coding-for-kids.html" class="navigation-text">coding for kids</a>
    </nav>

    <div class="content">
        <aside>
            Adam
            ZAYED-CITY
            PALISTINE
        </aside>
        <main>
            <article>
                <h1>Artificial intelligence (AI), data and criminal justice</h1>
                <p>Law enforcement and criminal justice authorities are increasingly using artificial intelligence (AI) and automated decision-making (ADM) systems in their work.

                    These systems can be used to profile people as criminal, ‘predict’ their actions, and assess their risk of certain behaviour, such as committing a crime, in the future. This can have devastating consequences for the people involved, if they are profiled as criminals or considered a ‘risk’ even though they haven’t actually committed a crime.
                    
                    These criminal ‘prediction’ systems or ‘predictive’ policing are no longer confined to the realms of science fiction. These systems are being used by law enforcement around the world. And predictions, profiles, and risk assessments that are based on data analysis, algorithms and AI, often lead to real criminal justice outcomes. This can include monitoring or surveillance, repeated stop and search, questioning, fines and arrests. These systems can also heavily influence prosecution, sentencing and probation decisions
                <h2>Predictive’ policing & criminal ‘prediction’ systems</h2>
                <p>Law enforcement and criminal justice authorities are increasingly using big data, algorithms and artificial intelligence (AI) to profile people and ‘predict’ whether they are likely to commit a crime.

                    ‘Predictive’ policing and criminal ‘prediction’ systems have been proven time and time again to reinforce discrimination and undermine fundamental rights, including the right to a fair trial and the presumption of innocence. This results in Black people, Roma, and other minoritised ethnic people being overpoliced and disproportionately detained and imprisoned across Europe.
                    
                    For example, in the Netherlands, the ‘Top 600’ list attempts to ‘predict’ which young people will commit certain crimes. One in three of the ‘Top 600’ – many of whom have reported being followed and harassed by police –  are of Moroccan descent. In Italy, a predictive system used by police called Delia includes ethnicity data to profile and ‘predict’ people’s future criminality. Other systems seek to ‘predict’ where crime will be committed, repeatedly targeting areas with high populations of racialised people or more deprived communities.
                    </p>
                    <h2>Databases & data in policing and criminal justice</h2>
                <p>
                    Across the world, police and criminal justice authorities hold vast databases, containing huge amounts of information about people, events and alleged crimes. This data includes police reports, incidents, and cautions and convictions, as well as images, addresses, associates, vehicles and other property, and data about people’s race or ethnicity, gender, nationality and more. They can also include police ‘intelligence’ – often uncorroborated information about people’s alleged involvement in crime or other activity.

Crime data is a record of the activity and decisions of police and criminal justice authorities, documenting the crimes, locations and groups that are most policed and criminalised in society. As such, the data held on those databases reflects the structural biases and inequalities in society, along lines of race, class, gender and other factors. For example, in the UK, Black people are policed and criminalised disproportionately more than white people on any measurement: stop and search, arrest, prosecution, pre-trial detention, imprisonment and more.

This data is used to justify or influence policing and criminal justice decisions, sometimes via ‘predictive’ or profiling systems, such as further monitoring, stop and search, questioning, arrest, prosecution, sentencing and probation. Increasingly, this information is also shared with other public authorities, affecting crucial, even life-changing decisions on immigration, housing, benefits, child custody or protection, and even punishment or exclusion in schools.</p>
